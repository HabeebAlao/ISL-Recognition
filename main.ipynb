{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter detected from input image:  D\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Program Description: ISL-Recognition Program\n",
    "\n",
    "Development Environment: This program was developed in Visual Studio Code.\n",
    "\n",
    "Authors: Habeeb Alao, Oluwamayowa Adelaja, Ida Bamfi\n",
    "\n",
    "Created: 25/10/2023    Modified: 30/11/2023\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import string \n",
    "\n",
    "\n",
    "def preprocessing_and_feature_extraction(I: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Author: Habeeb Alao\n",
    "\n",
    "    Outline of methods / algorithms used in preprocessing and feature extraction:\n",
    "\n",
    "    Identification of Hand using skin detection:\n",
    "        - This function looks for a hand in an input image using skin detection.\n",
    "        - using predertmined color threshold values the skin region in the image is extracted.\n",
    "        \n",
    "    Gamma Correction:\n",
    "        - This function applies a power transformation to adjust pixel values.\n",
    "        - which effectivley modifies the relationship between the pixel values and the brightness to better match the characteristics of the display device or the human eye.\n",
    "        \n",
    "    Masking / Segmentation: \n",
    "        - This function uses the mask that got from performing skin detection to ectract the edges of the hand from the original rgb image.\n",
    "        - with this we can see the isolated hand from the background\n",
    "\n",
    "    Morphology (erosion, dialtion, opening and closing):\n",
    "        -  Morphology is used in this function to remove excess mask info that may have been included after performing the inittail\n",
    "        thresholding.\n",
    "        - A variety of morphology techniques are used in this function including: erosion, dialtion, opening and closing. These techniques in conjunction \n",
    "        with eachother help refine the mask of the region of interest and remove excess binary pixles.\n",
    "    \n",
    "    Edge / Canny detection:\n",
    "        - This function finds the edges of the hand using canny edge detection.\n",
    "\n",
    "    Citations(IEEE format):\n",
    "\n",
    "    [1]\tS. Rahman, M. M. Rahman, M. Abdullah-Al-Wadud, G. D. Al-Quaderi, and M. Shoyaib, \n",
    "        “An adaptive gamma correction for image enhancement,” EURASIP J. Image Video Process., \n",
    "        vol. 2016, no. 1, p. 35, Oct. 2016, doi: 10.1186/s13640-016-0138-1.\n",
    "\n",
    "    [2] W. Kubinger, M. Vincze, and M. Ayromlou, “The role of gamma correction in colour image processing,” \n",
    "        in 9th European Signal Processing Conference (EUSIPCO 1998), Sep. 1998, pp. 1-4. Accessed: Oct. 28, 2023. \n",
    "        [Online]. Available: https://ieeexplore.ieee.org/abstract/document/7090032\n",
    "\n",
    "    [3] K. Nimisha and A. Jacob, “A Brief Review of the Recent Trends in Sign Language Recognition,” \n",
    "        in 2020 International Conference on Communication and Signal Processing (ICCSP), Jul. 2020, \n",
    "        pp. 186-190. doi: 10.1109/ICCSP48568.2020.9182351.\n",
    "\n",
    "    [4] M. Safeel, T. Sukumar, S. K. S, A. M. D, S. R, and P. S. B, “Sign Language Recognition Techniques- A Review,”\n",
    "        in 2020 IEEE International Conference for Innovation in Technology (INOCON), Nov. 2020, pp. 1-9. \n",
    "        doi: 10.1109/INOCON50539.2020.9298376.\n",
    "\n",
    "    [5] D. Team, “Sign Language Recognition Using Python and OpenCV,” \n",
    "        DataFlair. Accessed: Oct. 04, 2023. [Online]. Available: https://data-flair.training/blogs/sign-language-recognition-python-ml-opencv/\n",
    "\n",
    "    [6] M. Garimella, “Sign Language Recognition with Advanced Computer Vision,” \n",
    "        Medium. Accessed: Oct. 04, 2023. [Online]. Available: https://towardsdatascience.com/sign-language-recognition-with-advanced-computer-vision-7b74f20f3442\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    original_rgb = cv2.cvtColor(I, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # gamma correction on region of interest to enhance original color of hand\n",
    "    gamma = 0.5\n",
    "    copy_of_original = original_rgb.astype(float) / 255.0\n",
    "    copy_of_original = np.power(copy_of_original, gamma)\n",
    "    gamma_corrected_image = np.clip(copy_of_original * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "    gamma_corrected_image_bgr = cv2.cvtColor(gamma_corrected_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # converting from bgr to YCbCr color space\n",
    "    original_YCrCb = cv2.cvtColor(gamma_corrected_image_bgr, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    # skin color range for hsv color space \n",
    "    YCrCb_mask = cv2.inRange(original_YCrCb, (0, 135, 85), (255,180,135)) \n",
    "    YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "    # erosion with rect shape\n",
    "    shape = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "    mask_erosion = cv2.erode(YCrCb_mask,shape)\n",
    "    \n",
    "    # dilation\n",
    "    shape = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(1,2))\n",
    "    dialated_mask = cv2.dilate(mask_erosion,shape)\n",
    "\n",
    "    # opening\n",
    "    shape = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2,1))\n",
    "    opened_mask = cv2.morphologyEx(dialated_mask,cv2.MORPH_OPEN,shape)\n",
    "\n",
    "    # closing\n",
    "    shape = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,5))\n",
    "    closed_mask = cv2.morphologyEx(opened_mask,cv2.MORPH_CLOSE,shape)\n",
    "\n",
    "    # extract skin region using cleaned mask\n",
    "    skin_region = cv2.bitwise_and(original_rgb, original_rgb, mask = closed_mask)\n",
    "\n",
    "    # extract edges of the input image\n",
    "    edge_mask = cv2.Canny(skin_region,threshold1=220,threshold2=250)\n",
    "    \n",
    "    return edge_mask\n",
    "\n",
    "def getting_template_images(I):\n",
    "    \"\"\"\n",
    "    Author: Oluwamayowa Adelaja\n",
    "\n",
    "    Outline of methods / algorithms used in getting template images features:\n",
    "\n",
    "\n",
    "    ...\n",
    "\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply thresholding or other preprocessing if needed\n",
    "    _, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sort contours based on the y-coordinate of the bounding box\n",
    "    contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[1])\n",
    "\n",
    "    # Define a threshold for a new row\n",
    "    row_threshold = 30\n",
    "\n",
    "    # Group contours into rows\n",
    "    rows = []\n",
    "    current_row = [contours[0]]\n",
    "\n",
    "    for i in range(1, len(contours)):\n",
    "        x, y, w, h = cv2.boundingRect(contours[i])\n",
    "        _, prev_y, _, _ = cv2.boundingRect(current_row[-1])\n",
    "\n",
    "        # Check if a new row has started\n",
    "        if abs(y - prev_y) > row_threshold:\n",
    "            rows.append(current_row)\n",
    "            current_row = []\n",
    "\n",
    "        current_row.append(contours[i])\n",
    "\n",
    "    # Add the last row\n",
    "    rows.append(current_row)\n",
    "\n",
    "    # Sort contours within each row based on x-coordinate\n",
    "    for i, row in enumerate(rows):\n",
    "        rows[i] = sorted(row, key=lambda c: cv2.boundingRect(c)[0])\n",
    "\n",
    "    templates = []\n",
    "\n",
    "    # Process each row\n",
    "    for i, row in enumerate(rows):\n",
    "        for j, contour in enumerate(row):\n",
    "            if (i % 2 != 1):\n",
    "                # Extract the letter image using the bounding box\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                letter_image = I[y:y+h, x:x+w]\n",
    "\n",
    "                template = cv2.Canny(letter_image,threshold1=220,threshold2=250)\n",
    "\n",
    "                templates.append(template)\n",
    "\n",
    "    return templates\n",
    "\n",
    "def template_matching(input_mask, templates):\n",
    "    \"\"\"\n",
    "    Author: Ida Bamfi\n",
    "\n",
    "    Outline of methods / algorithms used in template matching:\n",
    "    ...\n",
    "\n",
    "    \"\"\"\n",
    "    alphabet = {}\n",
    "    count = 0\n",
    "    \n",
    "    for i in string.ascii_uppercase:\n",
    "        alphabet[i] = count\n",
    "        count += 1\n",
    "\n",
    "    input_image = cv2.Canny(input_mask,threshold1=220,threshold2=250)\n",
    "    best_match_score = -1\n",
    "\n",
    "    for i in range(0, len(templates)):\n",
    "        # Apply template matching\n",
    "        result = cv2.matchTemplate(input_image, templates[i], cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "        # Get the maximum correlation score and its location\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "        # Check if this match is better than the previous best match\n",
    "        if max_val > best_match_score:\n",
    "            best_match_score = max_val\n",
    "            best_template = templates[i]\n",
    "            letter = i\n",
    "        \n",
    "    return \"\".join([j for j in alphabet if alphabet[j] == letter])\n",
    "\n",
    "\n",
    "def isl_detection(I: np.ndarray, T: np.ndarray):\n",
    "    \"\"\"\n",
    "\n",
    "    Program Description: ISL-Recognition Program using:\n",
    "        - preprocessing and feture extraction\n",
    "        - template feature extraction \n",
    "        - template matching\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # preprocessing and feture extraction \n",
    "    input_mask = preprocessing_and_feature_extraction(I)\n",
    "\n",
    "    # template feature extraction\n",
    "    templates = getting_template_images(T)\n",
    "\n",
    "    # template matching\n",
    "    isl_letter = template_matching(input_mask, templates)\n",
    "    \n",
    "    return isl_letter\n",
    "    \n",
    "\n",
    "# image imports\n",
    "input_image = cv2.imread('./sample-input.jpg')\n",
    "template_image = cv2.imread('./isl-finger-sp.jpg')\n",
    "\n",
    "# calling ISL detection function\n",
    "detected_letter = isl_detection(input_image, template_image)\n",
    "\n",
    "print(\"Letter detected from input image: \", detected_letter )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
